# Exercise 4.9

There are at least two interpretations of "representing [the store]
as a Scheme vector".  The most obvious one is to use a fixed-size
vector and to maintain an index value which points to the next free
location in the store.  This makes all of the reference operations as
fast as the underlying vector-ref and vector-set! procedures.  Of
course, the downside is that such a store is very finite, and
exceeding the arbitrary store size will cause an out-of-memory error.

Another interpretation is to have a dynamically growing vector, using
vector-append to create new locations.  This avoids the arbitrary
memory limit but makes newref very space-expensive.

The best approach to a vector store is to use flexible vectors, which
are common in recent imperative languages.  A good implementation of
those would give you constant-time access and amortized constant-time
insert, without the arbitrary index-space limit.

The exercise asks "what is lost by using this representation?"  Using
a statically-sized vector-based store, we lose the ability to run
arbitrary programs without running out of memory--a program could
always need one more location than we've allocated.  You might say
that the same problem exists with any program, but the difference here
is the initialization overhead.  We can also run out of (Scheme)
memory with a list representation, but there initialize-store! runs in
constant space and time.  Allocating a vector "big enough for all
practical purposes" could be very expensive if those purposes require
thousands of locations.  So the fast store operations of this
representation come with either massive space usage out of the gate,
or with very limited store space.
